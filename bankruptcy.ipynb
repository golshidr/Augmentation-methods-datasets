{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/golshidr/Augmentation-methods-datasets/blob/main/bankruptcy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEIssPZbM9lU"
      },
      "source": [
        "# **import library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsEe2wE1OqNz",
        "outputId": "18b10a28-ff72-4dcb-8137-1fd7850c3d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiC6nVijQw4E",
        "outputId": "c50cedb1-0b78-4200-f6bb-169f1a59ab30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: DelftStack\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore', '.*do not.*', )\n",
        "warnings.warn('DelftStack')\n",
        "warnings.warn('Do not show this message')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QsXErinrYdH",
        "outputId": "cb3d7146-5bc5-445e-de35-c1fe476b55d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting impyute\n",
            "  Downloading impyute-0.0.8-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from impyute) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from impyute) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from impyute) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->impyute) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->impyute) (1.2.0)\n",
            "Installing collected packages: impyute\n",
            "Successfully installed impyute-0.0.8\n"
          ]
        }
      ],
      "source": [
        "pip install impyute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw-tNyzvrNVi",
        "outputId": "c9899da0-945d-4562-9ccb-1fc507a1dbf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fancyimpute\n",
            "  Downloading fancyimpute-0.7.0.tar.gz (25 kB)\n",
            "Collecting knnimpute>=0.1.0\n",
            "  Downloading knnimpute-0.1.0.tar.gz (8.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (1.0.2)\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (1.2.1)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (1.3.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (3.6.4)\n",
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 40.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.7/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.2.0)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.7/dist-packages (from cvxpy->fancyimpute) (2.0.10)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from cvxpy->fancyimpute) (0.6.2.post0)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from cvxpy->fancyimpute) (3.2.0)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp>=0.4.1->cvxpy->fancyimpute) (0.1.5.post2)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (1.11.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (1.4.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (22.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (57.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (8.14.0)\n",
            "Building wheels for collected packages: fancyimpute, knnimpute\n",
            "  Building wheel for fancyimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fancyimpute: filename=fancyimpute-0.7.0-py3-none-any.whl size=29899 sha256=ece335a7f21c721d504917e3f0b2b0045a8d556e17eb590a9ff4e5dbcdc27e08\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/04/06/a1a7d89ef4e631ce6268ea2d8cde04f7290651c1ff1025ce68\n",
            "  Building wheel for knnimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knnimpute: filename=knnimpute-0.1.0-py3-none-any.whl size=11353 sha256=7d520e3f0015f771b105752a9096022720f3cef1d4079fb653084786d20301b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/21/a8/a045cacd9838abd5643f6bfa852c0796a99d6b1494760494e0\n",
            "Successfully built fancyimpute knnimpute\n",
            "Installing collected packages: nose, knnimpute, fancyimpute\n",
            "Successfully installed fancyimpute-0.7.0 knnimpute-0.1.0 nose-1.3.7\n"
          ]
        }
      ],
      "source": [
        "pip install fancyimpute\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLo43M5XNX3E",
        "outputId": "1005ce01-f33e-45d5-92db-e76e656f9662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting arff\n",
            "  Downloading arff-0.9.tar.gz (4.7 kB)\n",
            "Building wheels for collected packages: arff\n",
            "  Building wheel for arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for arff: filename=arff-0.9-py3-none-any.whl size=4971 sha256=ee170cadc2e552c0ab0a3e17e39ca33fa6b815ed7521694648b0246c446e4399\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/81/bd/4ae90e24ba860304e375da219f9205b2586dbee255f3ee70e2\n",
            "Successfully built arff\n",
            "Installing collected packages: arff\n",
            "Successfully installed arff-0.9\n"
          ]
        }
      ],
      "source": [
        "pip install arff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsGpRNYorr_L"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "#imputer = SimpleImputer(missing_values=np.nan, strategy='mean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0L-9xF_qsZD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#To perform kFold Cross Validation\n",
        "from sklearn.model_selection import KFold\n",
        "# Formatted counter of class labels\n",
        "from collections import Counter\n",
        "# Ordered Dictionary\n",
        "from collections import OrderedDict\n",
        "# Library imbalanced-learn to deal with the data imbalance. To use SMOTE oversampling\n",
        "from imblearn.over_sampling import SMOTE \n",
        "\n",
        "# Impoting classification models\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.ensemble import BalancedBaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "import random\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import precision_recall_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "_M0ZUOGWsE9t",
        "outputId": "5370acdf-8159-4a71-8776-d962d83f6dcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                X1           X2           X3           X4            X5  \\\n",
              "count  7024.000000  7024.000000  7024.000000  6997.000000  7.019000e+03   \n",
              "mean      0.034660     0.560215     0.119969     2.629143 -2.631672e+02   \n",
              "std       4.565504     5.350084     5.275459    13.257356  3.707460e+04   \n",
              "min    -256.890000   -72.162000  -440.500000     0.000000 -2.722100e+06   \n",
              "25%       0.021182     0.296678     0.026968     1.063100 -4.449800e+01   \n",
              "50%       0.075802     0.482960     0.181275     1.502000 -5.373900e+00   \n",
              "75%       0.160268     0.680233     0.362548     2.460700  3.777050e+01   \n",
              "max      94.280000   441.500000     1.000000  1017.800000  9.909000e+05   \n",
              "\n",
              "                X6           X7           X8           X9          X10  ...  \\\n",
              "count  7024.000000  7024.000000  7002.000000  7026.000000  7024.000000  ...   \n",
              "mean      0.059712     0.313876     2.623996     5.552855     1.825832  ...   \n",
              "std       6.051113     8.353274    18.708327   101.995448    33.836452  ...   \n",
              "min    -397.890000  -189.560000  -141.410000     0.000005  -440.550000  ...   \n",
              "25%       0.000000     0.028023     0.445710     1.037225     0.300785  ...   \n",
              "50%       0.000000     0.090109     1.015100     1.205750     0.492235  ...   \n",
              "75%       0.146660     0.188667     2.267675     2.132975     0.675677  ...   \n",
              "max     303.670000   453.770000  1452.200000  3876.100000  1099.500000  ...   \n",
              "\n",
              "                X55           X56          X57           X58          X59  \\\n",
              "count  7.027000e+03  7.027000e+03  7026.000000  7.027000e+03  7026.000000   \n",
              "mean   8.855693e+03 -1.577367e+02     0.193243  1.587409e+02     0.277829   \n",
              "std    7.247527e+04  1.322125e+04     4.344046  1.322124e+04     6.339149   \n",
              "min   -8.004700e+05 -1.108300e+06  -315.370000 -4.194000e-03  -327.970000   \n",
              "25%    9.712000e+01  2.031450e-02     0.056772  8.647650e-01     0.000000   \n",
              "50%    1.604800e+03  6.338200e-02     0.175745  9.388100e-01     0.028438   \n",
              "75%    5.955900e+03  1.376950e-01     0.351922  9.820150e-01     0.273867   \n",
              "max    4.398400e+06  1.000000e+00   126.670000  1.108300e+06   119.580000   \n",
              "\n",
              "                X60           X61           X62          X63            X64  \n",
              "count  6.892000e+03   7005.000000  7.027000e+03  6997.000000    6993.000000  \n",
              "mean   4.328830e+02     15.642228  4.763202e+03     8.126852     208.731950  \n",
              "std    2.612802e+04    261.554534  3.107835e+05    19.996419    5140.708804  \n",
              "min    4.700000e-05      0.000016  0.000000e+00     0.000015       0.000010  \n",
              "25%    5.923950e+00      4.829000  4.322250e+01     3.425400       2.538600  \n",
              "50%    1.004050e+01      7.033700  6.850900e+01     5.303200       4.637700  \n",
              "75%    2.013900e+01     10.703000  1.063350e+02     8.357900       9.782200  \n",
              "max    2.137800e+06  21110.000000  2.501600e+07  1042.200000  294770.000000  \n",
              "\n",
              "[8 rows x 64 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c9257dc-c6a8-4c48-a4d9-ec2814163b68\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>...</th>\n",
              "      <th>X55</th>\n",
              "      <th>X56</th>\n",
              "      <th>X57</th>\n",
              "      <th>X58</th>\n",
              "      <th>X59</th>\n",
              "      <th>X60</th>\n",
              "      <th>X61</th>\n",
              "      <th>X62</th>\n",
              "      <th>X63</th>\n",
              "      <th>X64</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7024.000000</td>\n",
              "      <td>7024.000000</td>\n",
              "      <td>7024.000000</td>\n",
              "      <td>6997.000000</td>\n",
              "      <td>7.019000e+03</td>\n",
              "      <td>7024.000000</td>\n",
              "      <td>7024.000000</td>\n",
              "      <td>7002.000000</td>\n",
              "      <td>7026.000000</td>\n",
              "      <td>7024.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>7.027000e+03</td>\n",
              "      <td>7.027000e+03</td>\n",
              "      <td>7026.000000</td>\n",
              "      <td>7.027000e+03</td>\n",
              "      <td>7026.000000</td>\n",
              "      <td>6.892000e+03</td>\n",
              "      <td>7005.000000</td>\n",
              "      <td>7.027000e+03</td>\n",
              "      <td>6997.000000</td>\n",
              "      <td>6993.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.034660</td>\n",
              "      <td>0.560215</td>\n",
              "      <td>0.119969</td>\n",
              "      <td>2.629143</td>\n",
              "      <td>-2.631672e+02</td>\n",
              "      <td>0.059712</td>\n",
              "      <td>0.313876</td>\n",
              "      <td>2.623996</td>\n",
              "      <td>5.552855</td>\n",
              "      <td>1.825832</td>\n",
              "      <td>...</td>\n",
              "      <td>8.855693e+03</td>\n",
              "      <td>-1.577367e+02</td>\n",
              "      <td>0.193243</td>\n",
              "      <td>1.587409e+02</td>\n",
              "      <td>0.277829</td>\n",
              "      <td>4.328830e+02</td>\n",
              "      <td>15.642228</td>\n",
              "      <td>4.763202e+03</td>\n",
              "      <td>8.126852</td>\n",
              "      <td>208.731950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.565504</td>\n",
              "      <td>5.350084</td>\n",
              "      <td>5.275459</td>\n",
              "      <td>13.257356</td>\n",
              "      <td>3.707460e+04</td>\n",
              "      <td>6.051113</td>\n",
              "      <td>8.353274</td>\n",
              "      <td>18.708327</td>\n",
              "      <td>101.995448</td>\n",
              "      <td>33.836452</td>\n",
              "      <td>...</td>\n",
              "      <td>7.247527e+04</td>\n",
              "      <td>1.322125e+04</td>\n",
              "      <td>4.344046</td>\n",
              "      <td>1.322124e+04</td>\n",
              "      <td>6.339149</td>\n",
              "      <td>2.612802e+04</td>\n",
              "      <td>261.554534</td>\n",
              "      <td>3.107835e+05</td>\n",
              "      <td>19.996419</td>\n",
              "      <td>5140.708804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-256.890000</td>\n",
              "      <td>-72.162000</td>\n",
              "      <td>-440.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.722100e+06</td>\n",
              "      <td>-397.890000</td>\n",
              "      <td>-189.560000</td>\n",
              "      <td>-141.410000</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>-440.550000</td>\n",
              "      <td>...</td>\n",
              "      <td>-8.004700e+05</td>\n",
              "      <td>-1.108300e+06</td>\n",
              "      <td>-315.370000</td>\n",
              "      <td>-4.194000e-03</td>\n",
              "      <td>-327.970000</td>\n",
              "      <td>4.700000e-05</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.021182</td>\n",
              "      <td>0.296678</td>\n",
              "      <td>0.026968</td>\n",
              "      <td>1.063100</td>\n",
              "      <td>-4.449800e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.028023</td>\n",
              "      <td>0.445710</td>\n",
              "      <td>1.037225</td>\n",
              "      <td>0.300785</td>\n",
              "      <td>...</td>\n",
              "      <td>9.712000e+01</td>\n",
              "      <td>2.031450e-02</td>\n",
              "      <td>0.056772</td>\n",
              "      <td>8.647650e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.923950e+00</td>\n",
              "      <td>4.829000</td>\n",
              "      <td>4.322250e+01</td>\n",
              "      <td>3.425400</td>\n",
              "      <td>2.538600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.075802</td>\n",
              "      <td>0.482960</td>\n",
              "      <td>0.181275</td>\n",
              "      <td>1.502000</td>\n",
              "      <td>-5.373900e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090109</td>\n",
              "      <td>1.015100</td>\n",
              "      <td>1.205750</td>\n",
              "      <td>0.492235</td>\n",
              "      <td>...</td>\n",
              "      <td>1.604800e+03</td>\n",
              "      <td>6.338200e-02</td>\n",
              "      <td>0.175745</td>\n",
              "      <td>9.388100e-01</td>\n",
              "      <td>0.028438</td>\n",
              "      <td>1.004050e+01</td>\n",
              "      <td>7.033700</td>\n",
              "      <td>6.850900e+01</td>\n",
              "      <td>5.303200</td>\n",
              "      <td>4.637700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.160268</td>\n",
              "      <td>0.680233</td>\n",
              "      <td>0.362548</td>\n",
              "      <td>2.460700</td>\n",
              "      <td>3.777050e+01</td>\n",
              "      <td>0.146660</td>\n",
              "      <td>0.188667</td>\n",
              "      <td>2.267675</td>\n",
              "      <td>2.132975</td>\n",
              "      <td>0.675677</td>\n",
              "      <td>...</td>\n",
              "      <td>5.955900e+03</td>\n",
              "      <td>1.376950e-01</td>\n",
              "      <td>0.351922</td>\n",
              "      <td>9.820150e-01</td>\n",
              "      <td>0.273867</td>\n",
              "      <td>2.013900e+01</td>\n",
              "      <td>10.703000</td>\n",
              "      <td>1.063350e+02</td>\n",
              "      <td>8.357900</td>\n",
              "      <td>9.782200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>94.280000</td>\n",
              "      <td>441.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1017.800000</td>\n",
              "      <td>9.909000e+05</td>\n",
              "      <td>303.670000</td>\n",
              "      <td>453.770000</td>\n",
              "      <td>1452.200000</td>\n",
              "      <td>3876.100000</td>\n",
              "      <td>1099.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.398400e+06</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>126.670000</td>\n",
              "      <td>1.108300e+06</td>\n",
              "      <td>119.580000</td>\n",
              "      <td>2.137800e+06</td>\n",
              "      <td>21110.000000</td>\n",
              "      <td>2.501600e+07</td>\n",
              "      <td>1042.200000</td>\n",
              "      <td>294770.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 64 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c9257dc-c6a8-4c48-a4d9-ec2814163b68')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c9257dc-c6a8-4c48-a4d9-ec2814163b68 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c9257dc-c6a8-4c48-a4d9-ec2814163b68');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from scipy.sparse import data\n",
        "from scipy.io import arff\n",
        "############################################################\n",
        "# Loads the 5 raw .arff files into a list\n",
        "def load_arff_raw_data():\n",
        "    N=5\n",
        "    return [arff.loadarff('drive/MyDrive/' + str(i+1) + 'year.arff') for i in range(N)]\n",
        "\n",
        "############################################################\n",
        "# Loads the 5 raw .arff files into pandas dataframes\n",
        "def load_dataframes():\n",
        "    return [pd.DataFrame(data_i_year[0]) for data_i_year in load_arff_raw_data()]\n",
        "\n",
        "############################################################\n",
        "# Set the column headers from X1 ... X64 and the class label as Y, for all the 5 dataframes.\n",
        "def set_new_headers(dataframes):\n",
        "    cols = ['X' + str(i+1) for i in range(len(dataframes[0].columns)-1)]\n",
        "    cols.append('Y')\n",
        "    for df in dataframes:\n",
        "        df.columns = cols\n",
        "\n",
        "############################################################\n",
        "# dataframes is the list of pandas dataframes for the 5 year datafiles.  \n",
        "dataframes = load_dataframes()\n",
        "\n",
        "# Set the new headers for the dataframes. The new headers will have the renamed set of feature (X1 to X64)\n",
        "set_new_headers(dataframes)    \n",
        "\n",
        "# print the first 5 rows of a dataset 'year1'\n",
        "dataframes[0].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edL9oaRhOJSN"
      },
      "outputs": [],
      "source": [
        "# Convert the dtypes of all the columns (other than the class label columns) to float.\n",
        "def convert_columns_type_float(dfs):\n",
        "    for i in range(5):\n",
        "        index = 1\n",
        "        while(index<=63):\n",
        "            colname = dfs[i].columns[index]\n",
        "            col = getattr(dfs[i], colname)\n",
        "            dfs[i][colname] = col.astype(float)\n",
        "            index+=1\n",
        "            \n",
        "convert_columns_type_float(dataframes) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aud0r60YONat",
        "outputId": "9c1a0839-0a85-4b5a-ec86-6e8de9a3447a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7027, 65)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# The class labels for all the dataframes are originally in object type.\n",
        "# Convert them to int types\n",
        "def convert_class_label_type_int(dfs):\n",
        "    for i in range(len(dfs)):\n",
        "        col = getattr(dfs[i], 'Y')\n",
        "        dfs[i]['Y'] = col.astype(int)\n",
        "        \n",
        "convert_class_label_type_int(dataframes)\n",
        "dataframes[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isOQ2UFLONmC",
        "outputId": "c30c0cb4-4407-40a2-bd2f-c7e43799a419"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7027, 65)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#missing data using mean strategy\n",
        "def perform_mean_imputation(dfs):\n",
        "    # Construct an imputer with strategy as 'mean', to mean-impute along the columns\n",
        "    imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "    mean_imputed_dfs = [pd.DataFrame(imputer.fit_transform(df)) for df in dfs]\n",
        "    for i in range(len(dfs)):\n",
        "        mean_imputed_dfs[i].columns = dfs[i].columns   \n",
        "    return mean_imputed_dfs\n",
        "\n",
        "mean_imputed_dataframes = perform_mean_imputation(dataframes)\n",
        "dataframes[0].shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "YXw4sxuZbt5Q",
        "outputId": "2ecda433-6d9e-44d5-b6d6-8fac92001432"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                X1           X2           X3           X4            X5  \\\n",
              "count  7027.000000  7027.000000  7027.000000  7027.000000  7.027000e+03   \n",
              "mean      0.034660     0.560215     0.119969     2.629143 -2.631672e+02   \n",
              "std       4.564529     5.348941     5.274332    13.229022  3.705348e+04   \n",
              "min    -256.890000   -72.162000  -440.500000     0.000000 -2.722100e+06   \n",
              "25%       0.021208     0.296760     0.027011     1.064100 -4.462850e+01   \n",
              "50%       0.075790     0.483090     0.181180     1.505200 -5.575300e+00   \n",
              "75%       0.160240     0.680170     0.362500     2.476050  3.769500e+01   \n",
              "max      94.280000   441.500000     1.000000  1017.800000  9.909000e+05   \n",
              "\n",
              "                X6           X7           X8           X9          X10  ...  \\\n",
              "count  7027.000000  7027.000000  7027.000000  7027.000000  7027.000000  ...   \n",
              "mean      0.059712     0.313876     2.623996     5.552855     1.825832  ...   \n",
              "std       6.049821     8.351490    18.675013   101.988190    33.829227  ...   \n",
              "min    -397.890000  -189.560000  -141.410000     0.000005  -440.550000  ...   \n",
              "25%       0.000000     0.028037     0.447340     1.037250     0.300900  ...   \n",
              "50%       0.000000     0.090177     1.022100     1.206000     0.492450  ...   \n",
              "75%       0.146570     0.188880     2.286700     2.133150     0.675915  ...   \n",
              "max     303.670000   453.770000  1452.200000  3876.100000  1099.500000  ...   \n",
              "\n",
              "                X56          X57           X58          X59           X60  \\\n",
              "count  7.027000e+03  7027.000000  7.027000e+03  7027.000000  7.027000e+03   \n",
              "mean  -1.577367e+02     0.193243  1.587409e+02     0.277829  4.328830e+02   \n",
              "std    1.322125e+04     4.343737  1.322124e+04     6.338698  2.587579e+04   \n",
              "min   -1.108300e+06  -315.370000 -4.194000e-03  -327.970000  4.700000e-05   \n",
              "25%    2.031450e-02     0.056814  8.647650e-01     0.000000  6.013050e+00   \n",
              "50%    6.338200e-02     0.175820  9.388100e-01     0.028451  1.024900e+01   \n",
              "75%    1.376950e-01     0.351895  9.820150e-01     0.274140  2.136650e+01   \n",
              "max    1.000000e+00   126.670000  1.108300e+06   119.580000  2.137800e+06   \n",
              "\n",
              "                X61           X62          X63            X64            Y  \n",
              "count   7027.000000  7.027000e+03  7027.000000    7027.000000  7027.000000  \n",
              "mean      15.642228  4.763202e+03     8.126852     208.731950     0.038566  \n",
              "std      261.144719  3.107835e+05    19.953682    5128.255341     0.192571  \n",
              "min        0.000016  0.000000e+00     0.000015       0.000010     0.000000  \n",
              "25%        4.834250  4.322250e+01     3.432500       2.550300     0.000000  \n",
              "50%        7.046300  6.850900e+01     5.327800       4.657400     0.000000  \n",
              "75%       10.775500  1.063350e+02     8.326800       9.912750     0.000000  \n",
              "max    21110.000000  2.501600e+07  1042.200000  294770.000000     1.000000  \n",
              "\n",
              "[8 rows x 65 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0834318f-28fa-4f95-a32f-2c7cec4496da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>...</th>\n",
              "      <th>X56</th>\n",
              "      <th>X57</th>\n",
              "      <th>X58</th>\n",
              "      <th>X59</th>\n",
              "      <th>X60</th>\n",
              "      <th>X61</th>\n",
              "      <th>X62</th>\n",
              "      <th>X63</th>\n",
              "      <th>X64</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7027.000000</td>\n",
              "      <td>7027.000000</td>\n",
              "      <td>7027.000000</td>\n",
              "      <td>7027.000000</td>\n",
              "      <td>7.027000e+03</td>\n",
              "      <td>7027.000000</td>\n",
              "      <td>7027.000000</td>\n",
              "      <td>7027.000000</td>\n",
              "      <td>7027.000000</td>\n",
              "      <td>7027.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>7.027000e+03</td>\n",
              "      <td>7027.000000</td>\n",
              "      <td>7.027000e+03</td>\n",
              "      <td>7027.000000</td>\n",
              "      <td>7.027000e+03</td>\n",
              "      <td>7027.000000</td>\n",
              "      <td>7.027000e+03</td>\n",
              "      <td>7027.000000</td>\n",
              "      <td>7027.000000</td>\n",
              "      <td>7027.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.034660</td>\n",
              "      <td>0.560215</td>\n",
              "      <td>0.119969</td>\n",
              "      <td>2.629143</td>\n",
              "      <td>-2.631672e+02</td>\n",
              "      <td>0.059712</td>\n",
              "      <td>0.313876</td>\n",
              "      <td>2.623996</td>\n",
              "      <td>5.552855</td>\n",
              "      <td>1.825832</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.577367e+02</td>\n",
              "      <td>0.193243</td>\n",
              "      <td>1.587409e+02</td>\n",
              "      <td>0.277829</td>\n",
              "      <td>4.328830e+02</td>\n",
              "      <td>15.642228</td>\n",
              "      <td>4.763202e+03</td>\n",
              "      <td>8.126852</td>\n",
              "      <td>208.731950</td>\n",
              "      <td>0.038566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.564529</td>\n",
              "      <td>5.348941</td>\n",
              "      <td>5.274332</td>\n",
              "      <td>13.229022</td>\n",
              "      <td>3.705348e+04</td>\n",
              "      <td>6.049821</td>\n",
              "      <td>8.351490</td>\n",
              "      <td>18.675013</td>\n",
              "      <td>101.988190</td>\n",
              "      <td>33.829227</td>\n",
              "      <td>...</td>\n",
              "      <td>1.322125e+04</td>\n",
              "      <td>4.343737</td>\n",
              "      <td>1.322124e+04</td>\n",
              "      <td>6.338698</td>\n",
              "      <td>2.587579e+04</td>\n",
              "      <td>261.144719</td>\n",
              "      <td>3.107835e+05</td>\n",
              "      <td>19.953682</td>\n",
              "      <td>5128.255341</td>\n",
              "      <td>0.192571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-256.890000</td>\n",
              "      <td>-72.162000</td>\n",
              "      <td>-440.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.722100e+06</td>\n",
              "      <td>-397.890000</td>\n",
              "      <td>-189.560000</td>\n",
              "      <td>-141.410000</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>-440.550000</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.108300e+06</td>\n",
              "      <td>-315.370000</td>\n",
              "      <td>-4.194000e-03</td>\n",
              "      <td>-327.970000</td>\n",
              "      <td>4.700000e-05</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.021208</td>\n",
              "      <td>0.296760</td>\n",
              "      <td>0.027011</td>\n",
              "      <td>1.064100</td>\n",
              "      <td>-4.462850e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.028037</td>\n",
              "      <td>0.447340</td>\n",
              "      <td>1.037250</td>\n",
              "      <td>0.300900</td>\n",
              "      <td>...</td>\n",
              "      <td>2.031450e-02</td>\n",
              "      <td>0.056814</td>\n",
              "      <td>8.647650e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.013050e+00</td>\n",
              "      <td>4.834250</td>\n",
              "      <td>4.322250e+01</td>\n",
              "      <td>3.432500</td>\n",
              "      <td>2.550300</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.075790</td>\n",
              "      <td>0.483090</td>\n",
              "      <td>0.181180</td>\n",
              "      <td>1.505200</td>\n",
              "      <td>-5.575300e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090177</td>\n",
              "      <td>1.022100</td>\n",
              "      <td>1.206000</td>\n",
              "      <td>0.492450</td>\n",
              "      <td>...</td>\n",
              "      <td>6.338200e-02</td>\n",
              "      <td>0.175820</td>\n",
              "      <td>9.388100e-01</td>\n",
              "      <td>0.028451</td>\n",
              "      <td>1.024900e+01</td>\n",
              "      <td>7.046300</td>\n",
              "      <td>6.850900e+01</td>\n",
              "      <td>5.327800</td>\n",
              "      <td>4.657400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.160240</td>\n",
              "      <td>0.680170</td>\n",
              "      <td>0.362500</td>\n",
              "      <td>2.476050</td>\n",
              "      <td>3.769500e+01</td>\n",
              "      <td>0.146570</td>\n",
              "      <td>0.188880</td>\n",
              "      <td>2.286700</td>\n",
              "      <td>2.133150</td>\n",
              "      <td>0.675915</td>\n",
              "      <td>...</td>\n",
              "      <td>1.376950e-01</td>\n",
              "      <td>0.351895</td>\n",
              "      <td>9.820150e-01</td>\n",
              "      <td>0.274140</td>\n",
              "      <td>2.136650e+01</td>\n",
              "      <td>10.775500</td>\n",
              "      <td>1.063350e+02</td>\n",
              "      <td>8.326800</td>\n",
              "      <td>9.912750</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>94.280000</td>\n",
              "      <td>441.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1017.800000</td>\n",
              "      <td>9.909000e+05</td>\n",
              "      <td>303.670000</td>\n",
              "      <td>453.770000</td>\n",
              "      <td>1452.200000</td>\n",
              "      <td>3876.100000</td>\n",
              "      <td>1099.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>126.670000</td>\n",
              "      <td>1.108300e+06</td>\n",
              "      <td>119.580000</td>\n",
              "      <td>2.137800e+06</td>\n",
              "      <td>21110.000000</td>\n",
              "      <td>2.501600e+07</td>\n",
              "      <td>1042.200000</td>\n",
              "      <td>294770.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 65 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0834318f-28fa-4f95-a32f-2c7cec4496da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0834318f-28fa-4f95-a32f-2c7cec4496da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0834318f-28fa-4f95-a32f-2c7cec4496da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# dealing with nan data using mean strategy\n",
        "def claculate_nan(dfs):\n",
        "    for i in range(len(dfs)):\n",
        "      index=0\n",
        "      while(index<=63):\n",
        "        m = dfs[i].mean(axis=0)\n",
        "        dfs[i] = dfs[i].fillna(m)\n",
        "        index=index+1\n",
        "\n",
        "claculate_nan = claculate_nan(dataframes)\n",
        "dataframes[0].describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=dataframes[0].append(dataframes[1])"
      ],
      "metadata": {
        "id": "_tbW0LyDoAes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df.append(dataframes[2])"
      ],
      "metadata": {
        "id": "lLs7XpaloI7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2=df1.append(dataframes[3])"
      ],
      "metadata": {
        "id": "2Dn29RxOoReb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3=df2.append(dataframes[4])"
      ],
      "metadata": {
        "id": "JR05r6CdoYXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/drive/My Drive/pankruptcy_poland_dataset.csv')\n",
        "dd=df[df['Y'] == 1]\n",
        "dd.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOzcFophojZt",
        "outputId": "f9e1fac4-455a-4394-e2ba-a40cfc1a3df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2091, 66)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9wI3ag_DCBs",
        "outputId": "a8b64053-493a-4da7-f4d2-697a4faea506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7027, 65)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7bFd5cRMDPX"
      },
      "source": [
        "# Naive approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "_xE23Odr8bGW",
        "outputId": "08a4f877-ecbc-494d-d05a-e39059ab8efc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-89d3e3fd21e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0mdfs_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mnaive_approach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnaive_approach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-89d3e3fd21e1>\u001b[0m in \u001b[0;36mnaive_approach\u001b[0;34m(dfs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mnew_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mdf_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdfs_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'new_data' referenced before assignment"
          ]
        }
      ],
      "source": [
        "def naive_approach(dfs):\n",
        "    for i in range(0):\n",
        "        index = 0\n",
        "        df_1 = dfs[i].loc[dfs[i]['Y'] == 1]\n",
        "        df_0 = dfs[i].loc[dfs[i]['Y'] == 0]\n",
        "        n=(len(df_0)-len(df_1))\n",
        "        new_data=pd.DataFrame()\n",
        "        dfs_0=pd.DataFrame()\n",
        "        print('Shape of dataframe[0] in the first step:',dataframes[0].shape)\n",
        "        j=0\n",
        "        while(index<=64):\n",
        "            colname = df_1.columns[index]\n",
        "            col = getattr(df_1, colname)\n",
        "            max_value = col.max()\n",
        "            min_value = col.min()\n",
        "            random_float_list = []\n",
        "            j=0\n",
        "            # Generating data in each column\n",
        "            for i in range(0, n):\n",
        "              random_float_list.append(round(random.uniform(min_value, max_value), 5))\n",
        "              \n",
        "            np.reshape(random_float_list,(n,1))\n",
        "            new_data[df_1.columns[index]]=random_float_list\n",
        "            \n",
        "            index+=1\n",
        "            \n",
        "    new_data[new_data.columns[-1]] == 1\n",
        "    df_1=df_1.append(new_data)\n",
        "    dfs_0=df_0.append(df_1)\n",
        "    \n",
        "    print('shape of new data that has been generated:',new_data.shape)\n",
        "    print('Shape of class with label 1: ',df_1.shape)\n",
        "    print('Shape of class with label 0: ',df_0.shape)\n",
        "    print('Shape of dfs_0 at last: ',dfs_0.shape)\n",
        "    path = '/content/drive/My Drive/year1.csv'\n",
        "    with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
        "      dfs_0.to_csv(f)\n",
        "\n",
        "naive_approach=naive_approach(dataframes) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb9BKbBtOzIX",
        "outputId": "87e3bc88-1ffb-4220-96e4-e3aa30354783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of dataframe[0] in the first step: (7027, 65)\n",
            "                 X1            X2            X3            X4            X5  \\\n",
            "count  13512.000000  13512.000000  13512.000000  13512.000000  1.351200e+04   \n",
            "mean      -1.880888    -11.458265    -13.547695     -5.406901 -5.198312e+03   \n",
            "std        3.848492     13.092215     14.727490     12.688094  2.720958e+04   \n",
            "min     -256.890000    -72.162000   -440.500000    -14.114577 -2.722100e+06   \n",
            "25%       -3.956533    -24.481219    -28.357668    -14.114577 -1.054592e+04   \n",
            "50%       -0.086261      0.079781     -0.265160      0.557340 -3.514500e+02   \n",
            "75%        0.080474      0.498965      0.195227      1.550525 -2.588225e+00   \n",
            "max       94.280000    441.500000      1.000000   1017.800000  9.909000e+05   \n",
            "\n",
            "                 X6            X7            X8            X9           X10  \\\n",
            "count  13512.000000  13512.000000  13512.000000  13512.000000  13512.000000   \n",
            "mean     -12.298663     -1.729587     -5.547964      2.310669    -12.544845   \n",
            "std       13.584526      6.387109     15.928845     73.623596     28.616663   \n",
            "min     -397.890000   -189.560000   -141.410000     -1.202490   -440.550000   \n",
            "25%      -25.689920     -3.943839    -14.402917     -1.202490    -28.116587   \n",
            "50%       -0.249930     -0.085977      0.034770      0.757715      0.033679   \n",
            "75%        0.000000      0.095693      1.084000      1.240525      0.505737   \n",
            "max      303.670000    453.770000   1452.200000   3876.100000   1099.500000   \n",
            "\n",
            "       ...           X56           X57           X58           X59  \\\n",
            "count  ...  1.351200e+04  13512.000000  1.351200e+04  13512.000000   \n",
            "mean   ... -8.209679e+01     -9.635699  8.254713e+01     -0.379865   \n",
            "std    ...  9.534492e+03     10.700555  9.534488e+03      4.621981   \n",
            "min    ... -1.108300e+06   -315.370000 -1.467954e-02   -327.970000   \n",
            "25%    ... -1.350364e-01    -20.286118 -1.467954e-02     -1.092526   \n",
            "50%    ... -7.422950e-02     -0.242960  5.975900e-01      0.000000   \n",
            "75%    ...  6.780600e-02      0.185902  9.429275e-01      0.037035   \n",
            "max    ...  1.000000e+00    126.670000  1.108300e+06    119.580000   \n",
            "\n",
            "                X60           X61           X62           X63            X64  \\\n",
            "count  1.351200e+04  13512.000000  1.351200e+04  13512.000000   13512.000000   \n",
            "mean  -2.774747e+02      2.797654 -8.450582e+02     -9.638367      80.357621   \n",
            "std    1.867431e+04    188.791981  2.241897e+05     23.431850    3700.524981   \n",
            "min   -1.047202e+03    -11.120437 -6.922043e+03    -28.888358     -58.745912   \n",
            "25%   -1.047202e+03    -11.120437 -6.922043e+03    -28.888358     -58.745912   \n",
            "50%    2.681150e+00      2.521550  1.511050e+01      1.442300       0.814130   \n",
            "75%    1.071875e+01      7.258150  7.074500e+01      5.494600       4.870100   \n",
            "max    2.137800e+06  21110.000000  2.501600e+07   1042.200000  294770.000000   \n",
            "\n",
            "                  Y  \n",
            "count  13512.000000  \n",
            "mean       0.500000  \n",
            "std        0.500019  \n",
            "min        0.000000  \n",
            "25%        0.000000  \n",
            "50%        0.500000  \n",
            "75%        1.000000  \n",
            "max        1.000000  \n",
            "\n",
            "[8 rows x 65 columns]\n"
          ]
        }
      ],
      "source": [
        "def mean_approach(dfs):\n",
        "    for i in range(1):\n",
        "        index = 0\n",
        "        df_1 = dfs[i].loc[dfs[i]['Y'] == 1]\n",
        "        df_0 = dfs[i].loc[dfs[i]['Y'] == 0]\n",
        "        n=(len(df_0)-len(df_1))\n",
        "        new_data=pd.DataFrame()\n",
        "        dfs_0=pd.DataFrame()\n",
        "        print('Shape of dataframe[0] in the first step:',dataframes[0].shape)\n",
        "        j=0\n",
        "        while(index<=64):\n",
        "            colname = df_1.columns[index]\n",
        "            col = getattr(df_1, colname)\n",
        "            mean_value = col.mean()\n",
        "            max_value = col.max()\n",
        "            std_value=col.std()\n",
        "            min_value = col.min()\n",
        "            mean_float_list = []\n",
        "            j=0\n",
        "            # Generating data in each column\n",
        "            for i in range(0, n):\n",
        "              z= mean_value - std_value\n",
        "              mean_float_list.append(z)\n",
        "              \n",
        "\n",
        "            random.shuffle(mean_float_list)  \n",
        "            np.reshape(mean_float_list,(n,1))\n",
        "            new_data[df_1.columns[index]]=mean_float_list\n",
        "            \n",
        "            index+=1\n",
        "            \n",
        "    new_data[new_data.columns[-1]] == 1\n",
        "    df_1=df_1.append(new_data)\n",
        "    dfs_0=df_0.append(df_1)\n",
        "    \n",
        "    #print('shape of new data that has been generated:',new_data.shape)\n",
        "    #print('Shape of class with label 1: ',df_1.shape)\n",
        "    #print('Shape of class with label 0: ',df_0.shape)\n",
        "    #print('Shape of dfs_0 at last: ',dfs_0.shape)\n",
        "    path = '/content/drive/My Drive/year1.csv'\n",
        "    with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
        "      dfs_0.to_csv(f)\n",
        "    print(dfs_0.describe())\n",
        "\n",
        "mean_approach=mean_approach(dataframes) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8TYN-BBTfsg"
      },
      "source": [
        "# SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcwmKBZ6o4XC",
        "outputId": "3c4b76f7-9636-47cc-b5e2-98f03cf14feb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the shape of data befor oversampling: (5910, 65)\n",
            "the shape of data after oversampling: (11000, 64)\n",
            "Test: consfusion matrix :\n",
            " [[29 21]\n",
            " [12 38]]\n",
            "Test: consfusion matrix :\n",
            " [[ 9 41]\n",
            " [11 39]]\n",
            "Test: consfusion matrix :\n",
            " [[36 14]\n",
            " [15 35]]\n",
            "Test: consfusion matrix :\n",
            " [[10 40]\n",
            " [11 39]]\n",
            "Test: consfusion matrix :\n",
            " [[43  7]\n",
            " [ 5  5]]\n"
          ]
        }
      ],
      "source": [
        "#SMOTE\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
        "\n",
        "class_0_org = dataframes[4][dataframes[4]['Y'] == 0]\n",
        "class_1_org = dataframes[4][dataframes[4]['Y'] == 1]\n",
        "\n",
        "\n",
        "df=dataframes[4]\n",
        "print('the shape of data befor oversampling:',df.shape)\n",
        "\n",
        "X=df.iloc[:,1:64].values\n",
        "Y=df.iloc[:,-1].values\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 2)\n",
        "X, Y = sm.fit_resample(X, Y.ravel())\n",
        "\n",
        "X=pd.DataFrame(X)\n",
        "Y=pd.DataFrame(Y)\n",
        "df = pd.concat([X, Y], axis=1)\n",
        "print('the shape of data after oversampling:',df.shape)\n",
        "df.to_csv('/content/drive/My Drive/year4.csv')\n",
        "class_0 = df[df.iloc[:,-1] == 0]\n",
        "class_1 = df[df.iloc[:,-1] == 1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for j in range(0,len(class_1_org),100):\n",
        "  class_1_test=class_1_org.iloc[j:j+50] # extract from orginal data\n",
        "  class_1 = class_1.loc[:,~class_1.columns.duplicated()].reset_index(drop=True)\n",
        "  class_1_train=pd.concat([class_1, class_1_test]).drop_duplicates(keep=False)\n",
        "  class_1_train.drop(class_1_train.iloc[:, 63:], inplace = True, axis = 1)\n",
        "  class_1_train[\"Y\"] = 1\n",
        "\n",
        "  \n",
        "\n",
        "  class_0_test=class_0_org.iloc[j:j+50] # extract from orginal data\n",
        "  class_0 = class_0.loc[:,~class_0.columns.duplicated()].reset_index(drop=True)\n",
        "  class_0_train=pd.concat([class_0, class_0_test]).drop_duplicates(keep=False)\n",
        "  class_0_train.drop(class_0_train.iloc[:, 63:], inplace = True, axis = 1)\n",
        "  class_0_train[\"Y\"] = 0\n",
        "\n",
        "\n",
        "  train_data = class_1_train.append(class_0_train)\n",
        "  test_data = class_1_test.append(class_0_test)\n",
        "\n",
        "\n",
        "  \n",
        "  X_train=train_data.iloc[:,1:63].values\n",
        "  X_train=pd.DataFrame(X_train)\n",
        "  X_train = X_train.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "  Y_train=train_data.iloc[:,-1].values\n",
        "  Y_train=pd.DataFrame(Y_train)\n",
        "  Y_train = Y_train.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  X_test=test_data.iloc[:,1:63].values\n",
        "  \n",
        "  X_test=pd.DataFrame(X_test)\n",
        "  \n",
        "  Y_test=test_data.iloc[:,-1].values\n",
        "  Y_test=pd.DataFrame(Y_test)\n",
        "\n",
        "\n",
        "  model = KNeighborsClassifier(n_neighbors=5)\n",
        "  model.fit(X_train,Y_train.values.ravel())\n",
        "  Y_pred_train=model.predict(X_train)\n",
        "  Y_pred_test=model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "  print('Test: consfusion matrix :\\n',confusion_matrix(Y_test,Y_pred_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXzWTr-I3cxs"
      },
      "source": [
        "# K-Means-SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6xBeov8YT3f"
      },
      "outputs": [],
      "source": [
        "\"\"\"K-Means SMOTE oversampling method for class-imbalanced data\"\"\"\n",
        "\n",
        "# Authors: Felix Last\n",
        "# License: MIT\n",
        "\n",
        "import warnings\n",
        "import math\n",
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "from imblearn.over_sampling.base import BaseOverSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.exceptions import raise_isinstance_error\n",
        "from imblearn.utils import check_neighbors_object\n",
        "from imblearn.utils.deprecation import deprecate_parameter\n",
        "\n",
        "class KMeansSMOTE(BaseOverSampler):\n",
        "    \"\"\"Class to perform oversampling using K-Means SMOTE.\n",
        "\n",
        "    K-Means SMOTE works in three steps:\n",
        "\n",
        "    1. Cluster the entire input space using k-means.\n",
        "    2. Distribute the number of samples to generate across clusters:\n",
        "\n",
        "        1. Select clusters which have a high number of minority class samples.\n",
        "        2. Assign more synthetic samples to clusters where minority class samples are sparsely distributed.\n",
        "\n",
        "    3. Oversample each filtered cluster using SMOTE.\n",
        "\n",
        "    The method implements SMOTE and random oversampling as limit cases. Therefore, the following configurations\n",
        "    may be used to achieve the behavior of ...\n",
        "\n",
        "    ... SMOTE: ``imbalance_ratio_threshold=float('Inf'), kmeans_args={'n_clusters':1}``\n",
        "\n",
        "    ... random oversampling: ``imbalance_ratio_threshold=float('Inf'), kmeans_args={'n_clusters':1}, smote_args={'k_neighbors':0})``\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    sampling_strategy : str, dict, or callable, optional (default='auto')\n",
        "        Ratio to use for resampling the data set.\n",
        "\n",
        "        - If ``str``, has to be one of: (i) ``'minority'``: resample the\n",
        "          minority class; (ii) ``'majority'``: resample the majority class,\n",
        "          (iii) ``'not minority'``: resample all classes apart of the minority\n",
        "          class, (iv) ``'all'``: resample all classes, and (v) ``'auto'``:\n",
        "          correspond to ``'all'`` with for oversampling methods and ``'not\n",
        "          minority'`` for undersampling methods. The classes targeted will be\n",
        "          oversampled or undersampled to achieve an equal number of sample\n",
        "          with the majority or minority class.\n",
        "        - If ``dict``, the keys correspond to the targeted classes. The values\n",
        "          correspond to the desired number of samples.\n",
        "        - If callable, function taking ``y`` and returns a ``dict``. The keys\n",
        "          correspond to the targeted classes. The values correspond to the\n",
        "          desired number of samples.\n",
        "\n",
        "    random_state : int, RandomState instance or None, optional (default=None)\n",
        "        If int, ``random_state`` is the seed used by the random number\n",
        "        generator; If ``RandomState`` instance, random_state is the random\n",
        "        number generator; If ``None``, the random number generator is the\n",
        "        ``RandomState`` instance used by ``np.random``.\n",
        "        Will be copied to kmeans_args and smote_args if not explicitly passed there.\n",
        "\n",
        "    kmeans_args : dict, optional (default={})\n",
        "        Parameters to be passed to ``sklearn.cluster.KMeans`` or ``sklearn.cluster.MiniBatchKMeans``\n",
        "        (see ``use_minibatch_kmeans``). If n_clusters is not explicitly set, scikit-learn's\n",
        "        default will apply.\n",
        "\n",
        "    smote_args : dict, optional (default={})\n",
        "        Parameters to be passed to ``imblearn.over_sampling.SMOTE``. Note that ``k_neighbors`` is automatically\n",
        "        adapted without warning when a cluster is smaller than the number of neighbors specified.\n",
        "        `sampling_strategy` will be overwritten according to sampling_strategy passed to this class. `random_state`\n",
        "        will be passed from this class if none is specified.\n",
        "\n",
        "    imbalance_ratio_threshold : float or dict, optional (default=1.0)\n",
        "        Specify a threshold for a cluster's imbalance ratio  ``((majority_count + 1) / (minority_count + 1))``.\n",
        "        Only clusters with an imbalance ratio less than the threshold are oversampled. Use a dictionary to specify\n",
        "        different thresholds for different minority classes.\n",
        "\n",
        "    density_power : float, optional (default=None)\n",
        "        Used to compute the density of minority samples within each cluster. By default, the number of features will be used.\n",
        "\n",
        "    use_minibatch_kmeans : boolean, optional (default=True)\n",
        "        If False, use ``sklearn.cluster.KMeans``. If True, use ``sklearn.cluster.MiniBatchKMeans``.\n",
        "\n",
        "    n_jobs : int, optional (default=1)\n",
        "        The number of threads to open if possible. This parameter will be copied to ``kmeans_args`` and\n",
        "        ``smote_args`` if not explicitly passed there. Note: ``MiniBatchKMeans`` does not accept ``n_jobs``.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                sampling_strategy='auto',\n",
        "                random_state=None,\n",
        "                kmeans_args=None,\n",
        "                smote_args=None,\n",
        "                imbalance_ratio_threshold=1.0,\n",
        "                density_power=None,\n",
        "                use_minibatch_kmeans=True,\n",
        "                n_jobs=1,\n",
        "                **kwargs):\n",
        "        super(KMeansSMOTE, self).__init__(sampling_strategy=sampling_strategy, **kwargs)\n",
        "        if kmeans_args is None:\n",
        "            kmeans_args = {}\n",
        "        if smote_args is None:\n",
        "            smote_args = {}\n",
        "        self.imbalance_ratio_threshold = imbalance_ratio_threshold\n",
        "        self.kmeans_args = copy.deepcopy(kmeans_args)\n",
        "        self.smote_args = copy.deepcopy(smote_args)\n",
        "        self.random_state = random_state\n",
        "        self.n_jobs = n_jobs\n",
        "        self.use_minibatch_kmeans = use_minibatch_kmeans\n",
        "\n",
        "        self.density_power = density_power\n",
        "\n",
        "    def _cluster(self, X):\n",
        "        \"\"\"Run k-means to cluster the dataset\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : ndarray, shape (n_samples, n_features)\n",
        "            Matrix containing the data which have to be sampled.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        cluster_assignment : ndarray, shape (n_samples)\n",
        "            The corresponding cluster labels of ``X``.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.use_minibatch_kmeans:\n",
        "            from sklearn.cluster import MiniBatchKMeans as KMeans\n",
        "        else:\n",
        "            from sklearn.cluster import KMeans as KMeans\n",
        "\n",
        "        kmeans = KMeans(**self.kmeans_args)\n",
        "        if self.use_minibatch_kmeans and 'init_size' not in self.kmeans_args:\n",
        "            self.kmeans_args['init_size'] = min(2 * kmeans.n_clusters, X.shape[0])\n",
        "            kmeans = KMeans(**self.kmeans_args)\n",
        "\n",
        "        kmeans.fit_transform(X)\n",
        "        cluster_assignment = kmeans.labels_\n",
        "        # kmeans.labels_ does not use continuous labels,\n",
        "        # i.e. some labels in 0..n_clusters may not exist. Tidy up this mess.\n",
        "        return cluster_assignment\n",
        "\n",
        "    def _filter_clusters(self, X, y, cluster_assignment, minority_class_label):\n",
        "        \"\"\"Determine sampling weight for each cluster.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : ndarray, shape (n_samples, n_features)\n",
        "            Matrix containing the data which have to be sampled.\n",
        "        y : ndarray, shape (n_samples, )\n",
        "            Corresponding label for each sample in X.\n",
        "        cluster_assignment : ndarray, shape (n_samples)\n",
        "            The corresponding cluster labels of ``X``.\n",
        "        minority_class_label : int\n",
        "            Label of the minority class to filter by.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        sampling_weights : ndarray, shape (np.max(np.unique(cluster_assignment)),)\n",
        "            Vector of sampling weights for each cluster\n",
        "        \"\"\"\n",
        "        # compute the shape of the density factors\n",
        "        # since the cluster labels are not continuous, make it large enough\n",
        "        # to fit all values up to the largest cluster label\n",
        "        largest_cluster_label = np.max(np.unique(cluster_assignment))\n",
        "        sparsity_factors = np.zeros((largest_cluster_label + 1,), dtype=np.float64)\n",
        "        minority_mask = (y == minority_class_label)\n",
        "        sparsity_sum = 0\n",
        "        imbalance_ratio_threshold = self.imbalance_ratio_threshold\n",
        "        if isinstance(imbalance_ratio_threshold, dict):\n",
        "            imbalance_ratio_threshold = imbalance_ratio_threshold[minority_class_label]\n",
        "\n",
        "        for i in np.unique(cluster_assignment):\n",
        "            cluster = X[cluster_assignment == i]\n",
        "            mask = minority_mask[cluster_assignment == i]\n",
        "            minority_count = cluster[mask].shape[0]\n",
        "            majority_count = cluster[~mask].shape[0]\n",
        "            imbalance_ratio = (majority_count + 1) / (minority_count + 1)\n",
        "            if (imbalance_ratio < imbalance_ratio_threshold) and (minority_count > 1):\n",
        "                distances = euclidean_distances(cluster[mask])\n",
        "                non_diagonal_distances = distances[\n",
        "                    ~np.eye(distances.shape[0], dtype=np.bool)\n",
        "                ]\n",
        "                average_minority_distance = np.mean( non_diagonal_distances )\n",
        "                if average_minority_distance is 0: average_minority_distance = 1e-1 # to avoid division by 0\n",
        "                density_factor = minority_count / (average_minority_distance ** self.density_power)\n",
        "                sparsity_factors[i] = 1 / density_factor\n",
        "\n",
        "        # prevent division by zero; set zero weights in majority clusters\n",
        "        sparsity_sum = sparsity_factors.sum()\n",
        "        if sparsity_sum == 0:\n",
        "            sparsity_sum = 1 # to avoid division by zero\n",
        "        sparsity_sum = np.full(sparsity_factors.shape, sparsity_sum, np.asarray(sparsity_sum).dtype)\n",
        "        sampling_weights = (sparsity_factors / sparsity_sum)\n",
        "\n",
        "        return sampling_weights\n",
        "\n",
        "\n",
        "    def _fit_resample(self, X, y):\n",
        "        \"\"\"Resample the dataset.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : ndarray, shape (n_samples, n_features)\n",
        "            Matrix containing the data which have to be sampled.\n",
        "\n",
        "        y : ndarray, shape (n_samples, )\n",
        "            Corresponding label for each sample in X.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        X_resampled : ndarray, shape (n_samples_new, n_features)\n",
        "            The array containing the resampled data.\n",
        "\n",
        "        y_resampled : ndarray, shape (n_samples_new)\n",
        "            The corresponding labels of ``X_resampled``\n",
        "\n",
        "        \"\"\"\n",
        "        self._set_subalgorithm_params()\n",
        "\n",
        "        if self.density_power is None:\n",
        "            self.density_power = X.shape[1]\n",
        "\n",
        "        resampled = [ (X.copy(), y.copy()) ]\n",
        "        sampling_ratio = {k: v for k, v in self.sampling_strategy_.items()}\n",
        "        # sampling_strategy_ does not contain classes where n_samples 0\n",
        "        for class_label in np.unique(y):\n",
        "            if class_label not in sampling_ratio:\n",
        "                sampling_ratio[class_label] = 0\n",
        "        for minority_class_label, n_samples in sampling_ratio.items():\n",
        "            if n_samples == 0:\n",
        "                continue\n",
        "\n",
        "            cluster_assignment = self._cluster(X)\n",
        "            sampling_weights = self._filter_clusters(X, y, cluster_assignment, minority_class_label)\n",
        "            smote_args = self.smote_args.copy()\n",
        "            if np.count_nonzero(sampling_weights) > 0:\n",
        "                # perform k-means smote\n",
        "                for i in np.unique(cluster_assignment):\n",
        "                    cluster_X = X[cluster_assignment == i]\n",
        "                    cluster_y = y[cluster_assignment == i]\n",
        "                    if sampling_weights[i] > 0:\n",
        "                        # determine ratio for oversampling the current cluster\n",
        "                        target_ratio = {label: np.count_nonzero(cluster_y == label) for label in sampling_ratio}\n",
        "                        cluster_minority_count = np.count_nonzero(cluster_y == minority_class_label)\n",
        "                        generate_count = int(round(n_samples * sampling_weights[i]))\n",
        "                        target_ratio[minority_class_label] = generate_count + cluster_minority_count\n",
        "\n",
        "                        # make sure that cluster_y has more than 1 class, adding a random point otherwise\n",
        "                        remove_index = -1\n",
        "                        if np.unique(cluster_y).size < 2:\n",
        "                            remove_index = cluster_y.size\n",
        "                            cluster_X = np.append(cluster_X, np.zeros((1,cluster_X.shape[1])), axis=0)\n",
        "                            majority_class_label = next( key for key in sampling_ratio.keys() if key != minority_class_label )\n",
        "                            target_ratio[majority_class_label] = 1 + target_ratio[majority_class_label]\n",
        "                            cluster_y = np.append(cluster_y, np.asarray(majority_class_label).reshape((1,)), axis=0)\n",
        "\n",
        "                        # clear target ratio of labels not present in cluster\n",
        "                        for label in list(target_ratio.keys()):\n",
        "                            if label not in cluster_y:\n",
        "                                del target_ratio[label]\n",
        "\n",
        "                        # modify copy of the user defined smote_args to reflect computed parameters\n",
        "                        smote_args['sampling_strategy'] = target_ratio\n",
        "\n",
        "                        smote_args = self._validate_smote_args(smote_args, cluster_minority_count)\n",
        "                        oversampler = SMOTE(**smote_args)\n",
        "\n",
        "                        # if k_neighbors is 0, perform random oversampling instead of smote\n",
        "                        if 'k_neighbors' in smote_args and smote_args['k_neighbors'] == 0:\n",
        "                                oversampler_args = {}\n",
        "                                if 'random_state' in smote_args:\n",
        "                                    oversampler_args['random_state'] = smote_args['random_state']\n",
        "                                oversampler = RandomOverSampler(**oversampler_args)\n",
        "\n",
        "                        # finally, apply smote to cluster\n",
        "                        with warnings.catch_warnings():\n",
        "                            # ignore warnings about minority class getting bigger than majority class\n",
        "                            # since this would only be true within this cluster\n",
        "                            warnings.filterwarnings(action='ignore', category=UserWarning, message=r'After over-sampling, the number of samples \\(.*\\) in class .* will be larger than the number of samples in the majority class \\(class #.* \\-\\> .*\\)')\n",
        "                            cluster_resampled_X, cluster_resampled_y = oversampler.fit_resample(cluster_X, cluster_y)\n",
        "\n",
        "                        if remove_index > -1:\n",
        "                            # since SMOTE's results are ordered the same way as the data passed into it,\n",
        "                            # the temporarily added point is at the same index position as it was added.\n",
        "                            for l in [cluster_resampled_X, cluster_resampled_y, cluster_X, cluster_y]:\n",
        "                                np.delete(l, remove_index, 0)\n",
        "\n",
        "                        # add new generated samples to resampled\n",
        "                        resampled.append( (\n",
        "                            cluster_resampled_X[cluster_y.size:,:],\n",
        "                            cluster_resampled_y[cluster_y.size:]))\n",
        "            else:\n",
        "                # all weights are zero -> perform regular smote\n",
        "                warnings.warn('No minority clusters found for class {}. Performing regular SMOTE. Try changing the number of clusters.'.format(minority_class_label))\n",
        "                target_ratio = {label: np.count_nonzero(y == label) for label in sampling_ratio}\n",
        "                target_ratio[minority_class_label] = sampling_ratio[minority_class_label]\n",
        "                minority_count = np.count_nonzero(y == minority_class_label)\n",
        "                smote_args = self._validate_smote_args(smote_args, minority_count)\n",
        "                oversampler = SMOTE(**smote_args)\n",
        "                X_smote, y_smote = oversampler.fit_resample(X, y)\n",
        "                resampled.append((\n",
        "                    X_smote[y.size:,:],\n",
        "                    y_smote[y.size:]))\n",
        "\n",
        "\n",
        "        resampled = list(zip(*resampled))\n",
        "        if(len(resampled) > 0):\n",
        "            X_resampled = np.concatenate(resampled[0], axis=0)\n",
        "            y_resampled = np.concatenate(resampled[1], axis=0)\n",
        "        return X_resampled, y_resampled\n",
        "\n",
        "\n",
        "    def _validate_smote_args(self, smote_args, minority_count):\n",
        "        # determine max number of nearest neighbors considering sample size\n",
        "        max_k_neighbors =  minority_count - 1\n",
        "        # check if max_k_neighbors is violated also considering smote's default\n",
        "        smote = SMOTE(**smote_args)\n",
        "        if smote.k_neighbors > max_k_neighbors:\n",
        "            smote_args['k_neighbors'] = max_k_neighbors\n",
        "            smote = SMOTE(**smote_args)\n",
        "        return smote_args\n",
        "\n",
        "    def _set_subalgorithm_params(self):\n",
        "        # copy random_state to sub-algorithms\n",
        "        if self.random_state is not None:\n",
        "            if 'random_state' not in self.smote_args:\n",
        "                    self.smote_args['random_state'] = self.random_state\n",
        "            if 'random_state' not in self.kmeans_args:\n",
        "                self.kmeans_args['random_state'] = self.random_state\n",
        "\n",
        "        # copy n_jobs to sub-algorithms\n",
        "        if self.n_jobs is not None:\n",
        "            if 'n_jobs' not in self.smote_args:\n",
        "                    self.smote_args['n_jobs'] = self.n_jobs\n",
        "            if 'n_jobs' not in self.kmeans_args:\n",
        "                if not self.use_minibatch_kmeans:\n",
        "                    self.kmeans_args['n_jobs'] = self.n_jobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zqTgzmSZjDA",
        "outputId": "5327773f-82db-474e-d53f-729f5f718132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7027, 65)\n",
            "        X1       X2       X3      X4       X5       X6       X7       X8  \\\n",
            "0  0.20055  0.37951  0.39641  2.0472  32.3510  0.38825  0.24976  1.33050   \n",
            "1  0.20912  0.49988  0.47225  1.9447  14.7860  0.00000  0.25834  0.99601   \n",
            "2  0.24866  0.69592  0.26713  1.5548  -1.1523  0.00000  0.30906  0.43695   \n",
            "\n",
            "       X9      X10  ...      X56      X57      X58       X59     X60     X61  \\\n",
            "0  1.1389  0.50494  ...  0.12196  0.39718  0.87804  0.001924  8.4160  5.1372   \n",
            "1  1.6996  0.49788  ...  0.12130  0.42002  0.85300  0.000000  4.1486  3.2732   \n",
            "2  1.3090  0.30408  ...  0.24114  0.81774  0.76599  0.694840  4.9909  3.9510   \n",
            "\n",
            "       X62     X63      X64  Y  \n",
            "0   82.658  4.4158   7.4277  0  \n",
            "1  107.350  3.4000  60.9870  0  \n",
            "2  134.270  2.7185   5.2078  0  \n",
            "\n",
            "[3 rows x 65 columns]\n",
            "Class 0 has 6756 instances\n",
            "Class 1 has 271 instances\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:305: UserWarning: No minority clusters found for class 1. Performing regular SMOTE. Try changing the number of clusters.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 0 has 6756 instances after oversampling\n",
            "Class 1 has 6756 instances after oversampling\n",
            "Test: consfusion matrix :\n",
            " [[39 11]\n",
            " [37 13]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from imblearn.datasets import fetch_datasets\n",
        "#from kmeans_smote import KMeansSMOTE\n",
        "\n",
        "df=dataframes[0]\n",
        "print(df.shape)\n",
        "print(df.head(3))\n",
        "X=df.iloc[:,1:64].values\n",
        "y=df.iloc[:,-1].values\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
        "\n",
        "class_0_org = dataframes[0][dataframes[0]['Y'] == 0]\n",
        "class_1_org = dataframes[0][dataframes[0]['Y'] == 1]\n",
        "\n",
        "[print('Class {} has {} instances'.format(label, count))\n",
        " for label, count in zip(*np.unique(y, return_counts=True))]\n",
        "\n",
        "kmeans_smote = KMeansSMOTE(\n",
        "    kmeans_args={\n",
        "        'n_clusters': 100\n",
        "    },\n",
        "    smote_args={\n",
        "        'k_neighbors': 20\n",
        "    }\n",
        ")\n",
        "X_resampled, y_resampled = kmeans_smote.fit_resample(X, y)\n",
        "\n",
        "[print('Class {} has {} instances after oversampling'.format(label, count))\n",
        " for label, count in zip(*np.unique(y_resampled, return_counts=True))]\n",
        "\n",
        "\n",
        "X=pd.DataFrame(X_resampled)\n",
        "Y=pd.DataFrame(y_resampled)\n",
        "df = pd.concat([X, Y], axis=1)\n",
        "df.to_csv('/content/drive/My Drive/year0.csv')\n",
        "\n",
        "\n",
        "class_0 = df[df.iloc[:,-1] == 0]\n",
        "class_1 = df[df.iloc[:,-1] == 1]\n",
        "\n",
        "\n",
        "\n",
        "for j in range(0,len(class_1_org),500):\n",
        "  class_1_test=class_1_org.iloc[j:j+50] # extract from orginal data\n",
        "  class_1 = class_1.loc[:,~class_1.columns.duplicated()].reset_index(drop=True)\n",
        "  class_1_train=pd.concat([class_1, class_1_test]).drop_duplicates(keep=False)\n",
        "  class_1_train.drop(class_1_train.iloc[:, 63:], inplace = True, axis = 1)\n",
        "  class_1_train[\"Y\"] = 1\n",
        "\n",
        "  \n",
        "\n",
        "  class_0_test=class_0_org.iloc[j:j+50] # extract from orginal data\n",
        "  class_0 = class_0.loc[:,~class_0.columns.duplicated()].reset_index(drop=True)\n",
        "  class_0_train=pd.concat([class_0, class_0_test]).drop_duplicates(keep=False)\n",
        "  class_0_train.drop(class_0_train.iloc[:, 63:], inplace = True, axis = 1)\n",
        "  class_0_train[\"Y\"] = 0\n",
        "\n",
        "\n",
        "  train_data = class_1_train.append(class_0_train)\n",
        "  test_data = class_1_test.append(class_0_test)\n",
        "\n",
        "\n",
        "  \n",
        "  X_train=train_data.iloc[:,1:63].values\n",
        "  X_train=pd.DataFrame(X_train)\n",
        "  X_train = X_train.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "  Y_train=train_data.iloc[:,-1].values\n",
        "  Y_train=pd.DataFrame(Y_train)\n",
        "  Y_train = Y_train.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  X_test=test_data.iloc[:,1:63].values\n",
        "  \n",
        "  X_test=pd.DataFrame(X_test)\n",
        "  \n",
        "  Y_test=test_data.iloc[:,-1].values\n",
        "  Y_test=pd.DataFrame(Y_test)\n",
        "\n",
        "\n",
        "#svclassifier = SVC(kernel='poly')\n",
        "  #model = KNeighborsClassifier(n_neighbors=5)\n",
        "  model = BernoulliNB()\n",
        "  model.fit(X_train,Y_train.values.ravel())\n",
        "  Y_pred_train=model.predict(X_train)\n",
        "  Y_pred_test=model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "  print('Test: consfusion matrix :\\n',confusion_matrix(Y_test,Y_pred_test))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vcXsiv5p8N_"
      },
      "outputs": [],
      "source": [
        "from pandas.io.parsers.readers import read_csv\n",
        "df_aug=read_csv('/content/drive/My Drive/year1.csv')\n",
        "#df_aug.drop('Unnamed: 0',inplace=True,axis=1)\n",
        "#df_aug.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCoifCBzVVEx"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJfG4tvT_U3F",
        "outputId": "764613a2-710b-4d49-cc75-534e996aeaba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM in the fifth year:\n",
            "\n",
            "The shape of real data class 0:\n",
            " (5500, 65)\n",
            "The shape of real data class 1:\n",
            " (410, 65)\n",
            "The shape of generated data class 0:\n",
            " (5500, 65)\n",
            "The shape of generated data class 1:\n",
            " (410, 65)\n",
            "0.31173261681909387\n",
            "0.4574074074074074\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from imblearn.datasets import fetch_datasets\n",
        "from pandas.io.parsers.readers import read_csv\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "df=dataframes[4]\n",
        "#df=df.drop('Unnamed: 0',axis=1)\n",
        "\n",
        "X=df.iloc[:,1:64].values\n",
        "y=df.iloc[:,-1].values\n",
        "\n",
        "class_0_org = dataframes[4][dataframes[4]['Y'] == 0]\n",
        "class_1_org = dataframes[4][dataframes[4]['Y'] == 1]\n",
        "\n",
        "class_0 = df[df.iloc[:,-1] == 0]\n",
        "class_1 = df[df.iloc[:,-1] == 1]\n",
        "f1=0\n",
        "acc=0\n",
        "print('SVM in the fifth year:\\n')\n",
        "print('The shape of real data class 0:\\n',class_0_org.shape)\n",
        "print('The shape of real data class 1:\\n',class_1_org.shape)\n",
        "print('The shape of generated data class 0:\\n',class_0.shape)\n",
        "print('The shape of generated data class 1:\\n',class_1.shape)\n",
        "i=0\n",
        "for j in range(0,len(class_1_org),50):\n",
        "  i=i+1\n",
        "  class_1_test=class_1_org.iloc[j:j+50] # extract from orginal data\n",
        "  class_1 = class_1.loc[:,~class_1.columns.duplicated()].reset_index(drop=True)\n",
        "  class_1_train=pd.concat([class_1, class_1_test]).drop_duplicates(keep=False)\n",
        "  class_1_train.drop(class_1_train.iloc[:, 63:], inplace = True, axis = 1)\n",
        "  class_1_train[\"Y\"] = 1\n",
        "\n",
        "  \n",
        "\n",
        "  class_0_test=class_0_org.iloc[j:j+50] # extract from orginal data\n",
        "  class_0 = class_0.loc[:,~class_0.columns.duplicated()].reset_index(drop=True)\n",
        "  class_0_train=pd.concat([class_0, class_0_test]).drop_duplicates(keep=False)\n",
        "  class_0_train.drop(class_0_train.iloc[:, 63:], inplace = True, axis = 1)\n",
        "  class_0_train[\"Y\"] = 0\n",
        "\n",
        "\n",
        "  train_data = class_1_train.append(class_0_train)\n",
        "  test_data = class_1_test.append(class_0_test)\n",
        "\n",
        "\n",
        "  \n",
        "  X_train=train_data.iloc[:,1:63].values\n",
        "  X_train=pd.DataFrame(X_train)\n",
        "  X_train = X_train.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "  Y_train=train_data.iloc[:,-1].values\n",
        "  Y_train=pd.DataFrame(Y_train)\n",
        "  Y_train = Y_train.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  X_test=test_data.iloc[:,1:63].values\n",
        "  \n",
        "  X_test=pd.DataFrame(X_test)\n",
        "  \n",
        "  Y_test=test_data.iloc[:,-1].values\n",
        "  Y_test=pd.DataFrame(Y_test)\n",
        "\n",
        "\n",
        "  #model = KNeighborsClassifier(n_neighbors=5)\n",
        "  #model=RandomForestClassifier(n_estimators=1000)\n",
        "  #model=SVC(kernel='rbf')\n",
        "  #model = BernoulliNB()\n",
        "  #model = GaussianNB()\n",
        "  #model=MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(35,20), random_state=1,max_iter=1500)\n",
        "  model=SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=50)\n",
        "\n",
        "\n",
        "  model.fit(X_train,Y_train.values.ravel())\n",
        "  Y_pred_train=model.predict(X_train)\n",
        "  Y_pred_test=model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "  #print('Test: consfusion matrix :\\n',confusion_matrix(Y_test,Y_pred_test))\n",
        "  f1=f1+f1_score(Y_test,Y_pred_test)\n",
        "  acc=acc+accuracy_score(Y_test,Y_pred_test)\n",
        "\n",
        "print(f1/i)\n",
        "print(acc/i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l7zc4b_WPvd",
        "outputId": "61f88dd5-1714-40cf-e350-0e7af2ca5fb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5910, 65)\n",
            "Class 0 has 5500 instances\n",
            "Class 1 has 410 instances\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:192: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:196: RuntimeWarning: overflow encountered in double_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:197: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:204: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 0 has 5500 instances after oversampling\n",
            "Class 1 has 410 instances after oversampling\n",
            "Test: consfusion matrix :\n",
            " [[45  5]\n",
            " [15 35]]\n",
            "Test: consfusion matrix :\n",
            " [[37 13]\n",
            " [13 37]]\n",
            "Test: consfusion matrix :\n",
            " [[38 12]\n",
            " [22 28]]\n",
            "Test: consfusion matrix :\n",
            " [[43  7]\n",
            " [23 27]]\n",
            "Test: consfusion matrix :\n",
            " [[44  6]\n",
            " [16 34]]\n",
            "Test: consfusion matrix :\n",
            " [[43  7]\n",
            " [21 29]]\n",
            "Test: consfusion matrix :\n",
            " [[35 15]\n",
            " [18 32]]\n",
            "Test: consfusion matrix :\n",
            " [[45  5]\n",
            " [14 36]]\n",
            "Test: consfusion matrix :\n",
            " [[37 13]\n",
            " [ 3  7]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from imblearn.datasets import fetch_datasets\n",
        "from pandas.io.parsers.readers import read_csv\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "import numpy as np\n",
        "from imblearn.datasets import fetch_datasets\n",
        "#from kmeans_smote import KMeansSMOTE\n",
        "\n",
        "df=dataframes[4]\n",
        "print(df.shape)\n",
        "\n",
        "X=df.iloc[:,1:64].values\n",
        "y=df.iloc[:,-1].values\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
        "\n",
        "class_0_org = df[df['Y'] == 0]\n",
        "class_1_org = df[df['Y'] == 1]\n",
        "\n",
        "[print('Class {} has {} instances'.format(label, count))\n",
        " for label, count in zip(*np.unique(y, return_counts=True))]\n",
        "\n",
        "kmeans_smote = KMeansSMOTE(\n",
        "    kmeans_args={\n",
        "        'n_clusters': 100\n",
        "    },\n",
        "    smote_args={\n",
        "        'k_neighbors': 20\n",
        "    }\n",
        ")\n",
        "X_resampled, y_resampled = kmeans_smote.fit_resample(X, y)\n",
        "\n",
        "[print('Class {} has {} instances after oversampling'.format(label, count))\n",
        " for label, count in zip(*np.unique(y_resampled, return_counts=True))]\n",
        "\n",
        "\n",
        "X=pd.DataFrame(X_resampled)\n",
        "Y=pd.DataFrame(y_resampled)\n",
        "df = pd.concat([X, Y], axis=1)\n",
        "df.to_csv('/content/drive/My Drive/year0.csv')\n",
        "\n",
        "\n",
        "class_0 = df[df.iloc[:,-1] == 0]\n",
        "class_1 = df[df.iloc[:,-1] == 1]\n",
        "\n",
        "\n",
        "\n",
        "for j in range(0,len(class_1_org),50):\n",
        "  class_1_test=class_1_org.iloc[j:j+50] # extract from orginal data\n",
        "  class_1 = class_1.loc[:,~class_1.columns.duplicated()].reset_index(drop=True)\n",
        "  class_1_train=pd.concat([class_1, class_1_test]).drop_duplicates(keep=False)\n",
        "  class_1_train.drop(class_1_train.iloc[:, 63:], inplace = True, axis = 1)\n",
        "  class_1_train[\"Y\"] = 1\n",
        "\n",
        "  \n",
        "\n",
        "  class_0_test=class_0_org.iloc[j:j+50] # extract from orginal data\n",
        "  class_0 = class_0.loc[:,~class_0.columns.duplicated()].reset_index(drop=True)\n",
        "  class_0_train=pd.concat([class_0, class_0_test]).drop_duplicates(keep=False)\n",
        "  class_0_train.drop(class_0_train.iloc[:, 63:], inplace = True, axis = 1)\n",
        "  class_0_train[\"Y\"] = 0\n",
        "\n",
        "\n",
        "  train_data = class_1_train.append(class_0_train)\n",
        "  test_data = class_1_test.append(class_0_test)\n",
        "\n",
        "\n",
        "  \n",
        "  X_train=train_data.iloc[:,1:63].values\n",
        "  X_train=pd.DataFrame(X_train)\n",
        "  X_train = X_train.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "  Y_train=train_data.iloc[:,-1].values\n",
        "  Y_train=pd.DataFrame(Y_train)\n",
        "  Y_train = Y_train.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  X_test=test_data.iloc[:,1:63].values\n",
        "  \n",
        "  X_test=pd.DataFrame(X_test)\n",
        "  \n",
        "  Y_test=test_data.iloc[:,-1].values\n",
        "  Y_test=pd.DataFrame(Y_test)\n",
        "\n",
        "\n",
        "#svclassifier = SVC(kernel='poly')\n",
        "  #model = KNeighborsClassifier(n_neighbors=5)\n",
        "  model = BernoulliNB()\n",
        "  model.fit(X_train,Y_train.values.ravel())\n",
        "  Y_pred_train=model.predict(X_train)\n",
        "  Y_pred_test=model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "  print('Test: consfusion matrix :\\n',confusion_matrix(Y_test,Y_pred_test))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X12euKG54Zg5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "i0hOXpsdoNau",
        "outputId": "4230ae81-65c3-45a4-aabe-33f3dcbbfae8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP:\n",
            "\n",
            "The shape of real data class 0:\n",
            " (284315, 31)\n",
            "The shape of real data class 1:\n",
            " (492, 31)\n",
            "The shape of generated data class 0:\n",
            " (284315, 31)\n",
            "The shape of generated data class 1:\n",
            " (284315, 31)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-a102e805d3fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m   \u001b[0mY_pred_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0mY_pred_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m                     \u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 )\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             )\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/creditcard.csv')\n",
        "df_baseline=read_csv('/content/drive/My Drive/creditcard_baseline.csv')\n",
        "df_baseline=df_baseline.drop('Unnamed: 0',axis=1)\n",
        "\n",
        "X=df.iloc[:,1:30].values\n",
        "y=df.iloc[:,-1].values\n",
        "\n",
        "class_0_org = df[df['Class'] == 0]\n",
        "class_1_org = df[df['Class'] == 1]\n",
        "\n",
        "class_0 = df_baseline[df_baseline.iloc[:,-1] == 0]\n",
        "class_1 = df_baseline[df_baseline.iloc[:,-1] == 1]\n",
        "\n",
        "print('MLP:\\n')\n",
        "print('The shape of real data class 0:\\n',class_0_org.shape)\n",
        "print('The shape of real data class 1:\\n',class_1_org.shape)\n",
        "print('The shape of generated data class 0:\\n',class_0.shape)\n",
        "print('The shape of generated data class 1:\\n',class_1.shape)\n",
        "\n",
        "for j in range(0,len(class_1_org),50):\n",
        "  class_1_test=class_1_org.iloc[j:j+50] # extract from orginal data\n",
        "  class_1 = class_1.loc[:,~class_1.columns.duplicated()].reset_index(drop=True)\n",
        "  class_1_train=pd.concat([class_1, class_1_test]).drop_duplicates(keep=False)\n",
        "  class_1_train.drop(class_1_train.iloc[:, 30:], inplace = True, axis = 1)\n",
        "  class_1_train[\"Class\"] = 1\n",
        "\n",
        "  \n",
        "\n",
        "  class_0_test=class_0_org.iloc[j:j+50] # extract from orginal data\n",
        "  class_0 = class_0.loc[:,~class_0.columns.duplicated()].reset_index(drop=True)\n",
        "  class_0_train=pd.concat([class_0, class_0_test]).drop_duplicates(keep=False)\n",
        "  class_0_train.drop(class_0_train.iloc[:, 30:], inplace = True, axis = 1)\n",
        "  class_0_train[\"Class\"] = 0\n",
        "\n",
        "\n",
        "  train_data = class_1_train.append(class_0_train)\n",
        "  test_data = class_1_test.append(class_0_test)\n",
        "\n",
        "\n",
        "  \n",
        "  X_train=train_data.iloc[:,1:30].values\n",
        "  X_train=pd.DataFrame(X_train)\n",
        "  X_train = X_train.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "  Y_train=train_data.iloc[:,-1].values\n",
        "  Y_train=pd.DataFrame(Y_train)\n",
        "  Y_train = Y_train.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  X_test=test_data.iloc[:,1:30].values\n",
        "  \n",
        "  X_test=pd.DataFrame(X_test)\n",
        "  \n",
        "  Y_test=test_data.iloc[:,-1].values\n",
        "  Y_test=pd.DataFrame(Y_test)\n",
        "\n",
        "\n",
        "  #model = KNeighborsClassifier(n_neighbors=5)\n",
        "  model=RandomForestClassifier(n_estimators=1000)\n",
        "  #model=SVC(kernel='rbf')\n",
        "  #model = BernoulliNB()\n",
        "  #model = GaussianNB()\n",
        "  #model=MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(50,20), random_state=1,max_iter=150)\n",
        "  #model=SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=50)\n",
        "\n",
        "\n",
        "  model.fit(X_train,Y_train.values.ravel())\n",
        "  Y_pred_train=model.predict(X_train)\n",
        "  Y_pred_test=model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "  print('Test: consfusion matrix :\\n',confusion_matrix(Y_test,Y_pred_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "zXzWTr-I3cxs",
        "TCoifCBzVVEx"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMlo4QRZ042bLZ0MEX5x4+c",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}